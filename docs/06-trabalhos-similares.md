# Trabalhos Similares

> An√°lise de trabalhos relacionados √† previs√£o de surtos de dengue utilizando Machine Learning, Deep Learning e dados clim√°ticos.

---

## üìö Vis√£o Geral

Esta se√ß√£o apresenta trabalhos relevantes que abordam a previs√£o de casos de dengue utilizando diferentes abordagens metodol√≥gicas, com foco especial em:

- Modelos de Machine Learning e Deep Learning
- Uso de dados clim√°ticos e meteorol√≥gicos
- Aplica√ß√µes no contexto brasileiro
- Sistemas de vigil√¢ncia e alerta precoce

---

## üáßüá∑ Trabalho 1: InfoDengue - Sistema de Alerta Nacional

### üìã Informa√ß√µes Gerais

- **Plataforma**: [InfoDengue](https://info.dengue.mat.br/)
- **Institui√ß√µes**: FIOCRUZ, FGV/EMAp
- **Escopo**: Sistema nacional de vigil√¢ncia e alerta para dengue, zika e chikungunya
- **Status**: Operacional desde ~2015, atualiza√ß√£o semanal

### üéØ Objetivo

Fornecer alertas semanais sobre risco de surtos de dengue para munic√≠pios brasileiros, integrando dados epidemiol√≥gicos e clim√°ticos em tempo real.

### üîß Metodologia

#### Dados Utilizados
- **Epidemiol√≥gicos**: Casos notificados do SINAN (atualiza√ß√£o semanal)
- **Clim√°ticos**: Dados meteorol√≥gicos de esta√ß√µes locais
- **Populacional**: Dados censit√°rios do IBGE
- **Geogr√°ficos**: Informa√ß√µes municipais

#### T√©cnicas de Modelagem
- **Nowcasting**: Estimativa de casos em tempo real (corre√ß√£o de atraso de notifica√ß√£o)
- **Modelos estat√≠sticos**: Para estimativa de incid√™ncia corrigida
- **Indicadores de alerta**: Classifica√ß√£o em n√≠veis de risco (verde, amarelo, laranja, vermelho)
- **An√°lise espacial**: Identifica√ß√£o de condi√ß√µes favor√°veis √† transmiss√£o

### üìä Resultados e Contribui√ß√µes

#### Funcionalidades
- ‚úÖ **Relat√≥rios municipais e estaduais**: Atualiza√ß√£o semanal
- ‚úÖ **API p√∫blica**: Acesso program√°tico aos dados
- ‚úÖ **Visualiza√ß√µes interativas**: Mapas e gr√°ficos temporais
- ‚úÖ **Sistema de alertas**: Classifica√ß√£o por n√≠veis de aten√ß√£o

#### Impacto
- Usado por secretarias de sa√∫de em todo o Brasil
- Refer√™ncia para tomada de decis√£o em sa√∫de p√∫blica
- Integra√ß√£o com a√ß√µes de controle vetorial

### üí° Relev√¢ncia para este TCC

- **Fonte de dados**: InfoDengue pode fornecer dados processados e validados
- **Benchmark**: Sistema operacional para compara√ß√£o de performance
- **Metodologia**: T√©cnicas de nowcasting e defini√ß√£o de limiares de alerta
- **Valida√ß√£o**: Casos reais de uso em gest√£o de sa√∫de p√∫blica

### üîó Links
- Site principal: https://info.dengue.mat.br/
- Relat√≥rios: https://info.dengue.mat.br/report/
- API: https://info.dengue.mat.br/services/api

---

## üß† Trabalho 2: LSTM com SHAP para Previs√£o de Dengue no Brasil

### üìã Informa√ß√µes Gerais

- **T√≠tulo**: "Forecasting dengue across Brazil with LSTM neural networks and SHAP-driven lagged climate and spatial effects"
- **Autores**: Chen, X., Moraga, P.
- **Publica√ß√£o**: BMC Public Health (2025)
- **DOI**: 10.1186/s12889-025-22106-7
- **Tipo**: Artigo cient√≠fico (peer-reviewed)

### üéØ Objetivo

Desenvolver um modelo de previs√£o de dengue para o Brasil utilizando redes LSTM, incorporando efeitos clim√°ticos com lags temporais e efeitos espaciais, com interpretabilidade via SHAP.

### üîß Metodologia

#### Dados Utilizados
- **Per√≠odo**: Dados hist√≥ricos de dengue no Brasil
- **Vari√°veis clim√°ticas**: Temperatura, precipita√ß√£o, umidade (com diferentes lags temporais)
- **Vari√°veis espaciais**: Informa√ß√µes geogr√°ficas e de munic√≠pios vizinhos
- **Granularidade**: Municipal

#### T√©cnicas de Modelagem
- **Arquitetura**: LSTM (Long Short-Term Memory)
- **Feature engineering**: 
  - Lags clim√°ticos (explora√ß√£o de diferentes janelas temporais)
  - Efeitos espaciais (correla√ß√£o com munic√≠pios vizinhos)
- **Interpretabilidade**: SHAP (SHapley Additive exPlanations) para explicar contribui√ß√µes das features

#### Valida√ß√£o
- Valida√ß√£o temporal (train/test split temporal)
- M√©tricas de performance para previs√£o de s√©ries temporais

### üìä Resultados e Contribui√ß√µes

#### Principais Achados
- ‚úÖ **LSTM demonstrou boa adaptabilidade**: Captura padr√µes complexos e n√£o-lineares
- ‚úÖ **Robustez do modelo**: Performance consistente em diferentes regi√µes
- ‚úÖ **Import√¢ncia dos lags**: Identifica√ß√£o de janelas temporais √≥timas para vari√°veis clim√°ticas
- ‚úÖ **Efeitos espaciais**: Informa√ß√£o de munic√≠pios vizinhos melhora previs√µes
- ‚úÖ **Interpretabilidade**: SHAP permite entender quais features s√£o mais importantes

#### M√©tricas
- Performance superior a modelos baseline
- Capacidade de capturar sazonalidade e tend√™ncias

### üí° Relev√¢ncia para este TCC

- **Arquitetura LSTM**: Refer√™ncia para implementa√ß√£o de deep learning
- **SHAP para interpretabilidade**: T√©cnica essencial para explicar modelos complexos
- **An√°lise de lags**: Metodologia para identificar janelas temporais √≥timas
- **Efeitos espaciais**: Abordagem para incorporar informa√ß√£o geogr√°fica
- **Contexto brasileiro**: Estudo espec√≠fico para a realidade do Brasil

### üîó Links
- Artigo: https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-025-22106-7

---

## ü§ñ Trabalho 3: Machine Learning para Previs√£o de Dengue em Cidades Brasileiras

### üìã Informa√ß√µes Gerais

- **T√≠tulo**: "Machine-Learning-Based Forecasting of Dengue Fever in Brazilian Cities Using Epidemiologic and Meteorological Variables"
- **Autores**: Roster, K., Connaughton, C., Rodrigues, F.A.
- **Publica√ß√£o**: American Journal of Epidemiology (2022)
- **DOI**: 10.1093/aje/kwac090
- **PMID**: 35584963

### üéØ Objetivo

Desenvolver e comparar diferentes modelos de machine learning para previs√£o mensal de casos de dengue em cidades brasileiras, avaliando a contribui√ß√£o de vari√°veis epidemiol√≥gicas e meteorol√≥gicas.

### üîß Metodologia

#### Dados Utilizados
- **Per√≠odo**: 2007-2019 (12 anos)
- **Vari√°veis epidemiol√≥gicas**: Casos mensais hist√≥ricos de dengue
- **Vari√°veis meteorol√≥gicas**: Dados clim√°ticos locais
- **Escopo**: M√∫ltiplas cidades brasileiras (geograficamente diversas)
- **Horizonte de previs√£o**: 1 m√™s √† frente

#### Algoritmos Comparados
1. **Random Forest** (melhor desempenho geral)
2. **Gradient Boosting Regression**
3. **Feed-Forward Neural Network** (Rede Neural densa)
4. **Support Vector Regression (SVR)**
5. **Seasonal Naive Baseline** (baseline para compara√ß√£o)

#### Feature Selection
- Compara√ß√£o de diferentes m√©todos de sele√ß√£o de features
- Avalia√ß√£o da contribui√ß√£o de vari√°veis epidemiol√≥gicas vs meteorol√≥gicas

#### Valida√ß√£o
- Valida√ß√£o temporal (train/test split)
- Avalia√ß√£o out-of-sample
- An√°lise de erro por cidade

### üìä Resultados e Contribui√ß√µes

#### Principais Achados
- ‚úÖ **Random Forest com casos hist√≥ricos**: Melhor modelo geral
  - Treinado principalmente em casos mensais de dengue
  - Produziu menores erros que todos os outros modelos
- ‚úÖ **Variabilidade regional**: Diferentes modelos funcionam melhor em diferentes cidades
- ‚úÖ **Performance superior ao baseline**: Todos os modelos ML superaram o baseline sazonal ing√™nuo

#### M√©tricas
- **MAE mediano**: 12.2 casos por m√™s (todas as cidades)
- **MAE otimizado**: 11.9 casos (selecionando melhor modelo por cidade)
- Erros baixos considerando diversidade geogr√°fica

#### Contribui√ß√µes
- Demonstra√ß√£o da utilidade de **ensemble de √°rvores de decis√£o** para vigil√¢ncia de dengue
- Evid√™ncia de que **modelos espec√≠ficos por cidade** podem melhorar performance
- Valida√ß√£o em dataset geograficamente diverso (generaliza√ß√£o)

### üí° Relev√¢ncia para este TCC

- **Compara√ß√£o de algoritmos**: Metodologia para avaliar m√∫ltiplos modelos ML
- **Feature selection**: T√©cnicas para identificar vari√°veis mais importantes
- **Valida√ß√£o robusta**: Abordagem temporal e geogr√°fica
- **Benchmark brasileiro**: Resultados em cidades brasileiras para compara√ß√£o
- **Ensemble models**: Random Forest como forte baseline ML
- **An√°lise de heterogeneidade**: Necessidade de modelos espec√≠ficos por regi√£o

### üìà Implica√ß√µes Pr√°ticas

- Machine learning pode contribuir significativamente para vigil√¢ncia de dengue
- Modelos de ensemble (Random Forest, XGBoost) s√£o particularmente eficazes
- Import√¢ncia de valida√ß√£o em m√∫ltiplas cidades para garantir generaliza√ß√£o

### üîó Links
- PubMed: https://pubmed.ncbi.nlm.nih.gov/35584963/
- DOI: https://doi.org/10.1093/aje/kwac090

---

## üìä Compara√ß√£o entre os Trabalhos

| Aspecto | InfoDengue | Chen & Moraga (2025) | Roster et al. (2022) |
|---------|------------|----------------------|----------------------|
| **Tipo** | Sistema operacional | Pesquisa acad√™mica | Pesquisa acad√™mica |
| **Modelo principal** | Nowcasting + estat√≠stica | LSTM + SHAP | Random Forest |
| **Horizonte** | Tempo real (corre√ß√£o atraso) | Vari√°vel | 1 m√™s |
| **Dados clim√°ticos** | ‚úÖ Sim | ‚úÖ Sim (com lags) | ‚úÖ Sim |
| **Escopo geogr√°fico** | Nacional (todos munic√≠pios) | Brasil (municipal) | M√∫ltiplas cidades BR |
| **Interpretabilidade** | Relat√≥rios semanais | ‚úÖ SHAP | Feature importance |
| **Uso pr√°tico** | ‚úÖ Operacional | Pesquisa | Pesquisa |
| **Per√≠odo de dados** | Atualiza√ß√£o cont√≠nua | Hist√≥rico | 2007-2019 |
| **Espacialidade** | Mapas e an√°lise espacial | ‚úÖ Efeitos espaciais | Multi-cidades |

---

## üéØ Lacunas e Oportunidades para este TCC

### 1. Compara√ß√£o Sistem√°tica de M√©todos
- **Lacuna**: Poucos trabalhos comparam estat√≠stica, ML e DL no mesmo framework
- **Oportunidade**: Implementar SARIMA, XGBoost e LSTM com mesmos dados

### 2. An√°lise Regional de Lags
- **Lacuna**: Varia√ß√£o regional de lags clim√°ticos pouco explorada
- **Oportunidade**: An√°lise detalhada por regi√£o geogr√°fica (Norte, Nordeste, etc.)

### 3. Transfer Learning para Munic√≠pios Pequenos
- **Lacuna**: Munic√≠pios com poucos dados hist√≥ricos s√£o dif√≠ceis de modelar
- **Oportunidade**: Usar informa√ß√£o de munic√≠pios vizinhos (spatial features)

### 4. Pipeline Reproduz√≠vel e Open Source
- **Lacuna**: Muitos trabalhos n√£o disponibilizam c√≥digo ou dados
- **Oportunidade**: C√≥digo completo no GitHub, documenta√ß√£o detalhada, reproduz√≠vel

### 5. Integra√ß√£o de M√∫ltiplas Fontes Clim√°ticas
- **Lacuna**: Uso limitado a dados locais (esta√ß√µes)
- **Oportunidade**: Combinar INMET, CHIRPS, ERA5 (sat√©lite + reanalysis)

### 6. Sistema de Alerta Calibrado
- **Lacuna**: Limiares de alerta muitas vezes arbitr√°rios
- **Oportunidade**: Calibra√ß√£o baseada em dados, otimiza√ß√£o de precision/recall

---

## üìñ Outras Refer√™ncias Relevantes

### Trabalhos Citados nos Artigos
- **Xu et al. (2020)**: "Forecast of Dengue Cases in 20 Chinese Cities Based on the Deep Learning Method"
- **Patil & Pandya (2021)**: "Forecasting Dengue Hotspots Associated With Variation in Meteorological Parameters"
- **Sylvestre et al. (2022)**: "Data-driven methods for dengue prediction and surveillance using real-world and Big Data: A systematic review"

### Temas para Revis√£o Adicional
- Modelos epidemiol√≥gicos compartimentais (SIR, SEIR)
- Nowcasting para corre√ß√£o de atraso de notifica√ß√£o
- Modelos espa√ßo-temporais (STARIMA, ConvLSTM)
- Ensemble learning para s√©ries temporais
- Calibra√ß√£o de sistemas de alerta

---

## ‚úÖ Principais Aprendizados

### üî¨ Metodol√≥gicos

1. **Valida√ß√£o temporal √© essencial**: Train/test splits temporais evitam data leakage
2. **Feature engineering √© cr√≠tico**: Lags, m√©dias m√≥veis, anomalias clim√°ticas
3. **Interpretabilidade importa**: SHAP, feature importance para explicar modelos
4. **Ensemble models funcionam bem**: Random Forest, XGBoost consistentemente bons
5. **Deep Learning precisa justificativa**: LSTM √∫til para padr√µes complexos, mas requer mais dados

### üåç Contextuais

1. **Heterogeneidade regional**: Brasil √© diverso, modelos podem variar por regi√£o
2. **Dados clim√°ticos s√£o preditivos**: Temperatura, precipita√ß√£o, umidade relevantes
3. **Lags variam**: Rela√ß√£o clima-dengue tem defasagem temporal (2-12 semanas)
4. **Sistemas operacionais existem**: InfoDengue √© refer√™ncia nacional
5. **Generaliza√ß√£o √© desafio**: Modelos precisam funcionar em m√∫ltiplas cidades

---

## ÔøΩÔ∏è Tecnologias Escolhidas para o Projeto

Esta se√ß√£o descreve as ferramentas, plataformas e tecnologias que ser√£o utilizadas no desenvolvimento deste TCC, cobrindo aspectos de modelagem, armazenamento de dados, processamento e deployment.

---

### üíæ Armazenamento e Infraestrutura de Dados

#### Op√ß√£o 1: Google Cloud Platform (GCP) - **RECOMENDADO**

**Justificativa:**
- ‚úÖ **Cr√©ditos educacionais**: Google Cloud oferece $300 em cr√©ditos gratuitos + cr√©ditos adicionais para estudantes
- ‚úÖ **BigQuery**: Data warehouse escal√°vel ideal para s√©ries temporais
- ‚úÖ **Cloud Storage**: Armazenamento de dados brutos (SINAN, CHIRPS, ERA5)
- ‚úÖ **Vertex AI**: Plataforma integrada para ML/DL, notebooks gerenciados
- ‚úÖ **Earth Engine**: Acesso direto a dados clim√°ticos de sat√©lite

**Servi√ßos a serem utilizados:**

| Servi√ßo | Uso | Custo Estimado |
|---------|-----|----------------|
| **Cloud Storage** | Raw data (SINAN, clima) | ~$5/m√™s (50GB) |
| **BigQuery** | Data warehouse, queries SQL | ~$10/m√™s (200GB) |
| **Vertex AI Notebooks** | Jupyter Notebooks gerenciados | ~$20/m√™s (quando ativo) |
| **Vertex AI Training** | Treinamento de modelos (LSTM) | ~$10-30/job |
| **Cloud Run** | API de previs√£o + Dashboard | ~$5/m√™s |

**Total estimado:** $50-100/m√™s (coberto por cr√©ditos educacionais)

**Arquitetura proposta:**
```
Raw Data (Cloud Storage)
    ‚Üì
ETL (Cloud Functions / Dataflow)
    ‚Üì
BigQuery (Data Warehouse)
    ‚Üì
Vertex AI (Modeling)
    ‚Üì
Cloud Storage (Modelos treinados)
    ‚Üì
Cloud Run (API + Dashboard)
```

---

#### Op√ß√£o 2: Amazon Web Services (AWS)

**Justificativa:**
- ‚úÖ **AWS Educate**: Cr√©ditos gratuitos para estudantes
- ‚úÖ **S3**: Armazenamento de dados
- ‚úÖ **Athena**: Queries SQL sobre S3 (serverless)
- ‚úÖ **SageMaker**: Plataforma completa de ML/DL
- ‚úÖ **EC2**: M√°quinas virtuais para processamento pesado

**Servi√ßos equivalentes:**

| Servi√ßo AWS | Equivalente GCP | Uso |
|-------------|-----------------|-----|
| **S3** | Cloud Storage | Raw data |
| **Athena** | BigQuery | Data warehouse |
| **SageMaker** | Vertex AI | ML/DL platform |
| **Lambda** | Cloud Functions | ETL serverless |
| **EC2** | Compute Engine | VMs para processamento |

---

#### Op√ß√£o 3: Solu√ß√£o H√≠brida (Local + Cloud)

**Para or√ßamento limitado:**
- **Local (Laptop)**: Desenvolvimento, EDA, modelos pequenos
- **Google Colab Pro**: Treinamento de modelos DL (~$10/m√™s)
- **GitHub**: Versionamento de c√≥digo
- **PostgreSQL local + Parquet**: Armazenamento de dados processados
- **Streamlit Cloud**: Dashboard gratuito (500MB)

---

### ü§ñ Modelos e Bibliotecas de Machine Learning

#### Modelos Estat√≠sticos

**Bibliotecas:**
```python
# S√©ries Temporais Cl√°ssicas
statsmodels==0.14.0      # ARIMA, SARIMA, SARIMAX
prophet==1.1.5           # Prophet (Meta/Facebook)
pmdarima==2.0.4          # Auto-ARIMA
```

**Justificativa:**
- SARIMA: Baseline cl√°ssico, bem estabelecido na literatura
- Prophet: Robusto a dados faltantes, f√°cil interpreta√ß√£o de sazonalidade

---

#### Modelos de Machine Learning

**Bibliotecas:**
```python
# Ensemble Methods
scikit-learn==1.3.0      # Random Forest, Gradient Boosting
xgboost==2.0.0           # XGBoost (melhor performance em tabular)
lightgbm==4.1.0          # LightGBM (alternativa r√°pida)
catboost==1.2.0          # CatBoost (handling de categorias)

# Feature Engineering
featuretools==1.28.0     # Automated feature engineering
tsfresh==0.20.0          # Time series feature extraction
```

**Justificativa:**
- XGBoost: Estado da arte para dados tabulares, usado em Roster et al. (2022)
- Scikit-learn: Random Forest como baseline ML
- LightGBM/CatBoost: Alternativas para compara√ß√£o

---

#### Modelos de Deep Learning

**Bibliotecas:**
```python
# Deep Learning Frameworks
tensorflow==2.14.0       # Framework principal
keras==2.14.0            # API de alto n√≠vel
pytorch==2.1.0           # Alternativa (se necess√°rio)

# Arquiteturas Espec√≠ficas
tensorflow-addons==0.22.0  # Camadas adicionais
keras-tuner==1.4.0         # Hyperparameter tuning
```

**Arquiteturas a implementar:**
1. **LSTM** (Long Short-Term Memory): Baseline DL
2. **BiLSTM** (Bidirectional LSTM): Captura contexto passado e futuro
3. **GRU** (Gated Recurrent Unit): Alternativa mais leve
4. **CNN-LSTM**: H√≠brido para padr√µes espaciais e temporais

**Justificativa:**
- LSTM: Usado em Chen & Moraga (2025), padr√£o para s√©ries temporais
- TensorFlow/Keras: Ecosistema maduro, integra√ß√£o com Google Cloud

---

#### Modelos Pr√©-treinados do Hugging Face ü§ó

**Op√ß√µes a explorar:**

##### 1. TimeGPT (Nixtla)
```python
from nixtla import TimeGPT
```
- **Descri√ß√£o**: Modelo foundation pr√©-treinado para s√©ries temporais
- **Uso**: Zero-shot forecasting sem fine-tuning
- **Pr√≥s**: State-of-the-art, sem necessidade de treino
- **Contras**: API paga ap√≥s per√≠odo trial

##### 2. Chronos (Amazon)
```python
from chronos import ChronosPipeline
```
- **Descri√ß√£o**: Fam√≠lia de modelos transformer para forecasting
- **Modelos**: chronos-t5-tiny, chronos-t5-small, chronos-t5-base
- **Uso**: Fine-tuning em dados de dengue
- **Pr√≥s**: Open source, diferentes tamanhos, bons resultados
- **Contras**: Requer GPU para modelos maiores

##### 3. Lag-Llama
```python
from lag_llama import LagLlamaModel
```
- **Descri√ß√£o**: Modelo transformer pr√©-treinado especificamente para s√©ries temporais univariadas
- **Uso**: Fine-tuning ou zero-shot
- **Pr√≥s**: Especializado em forecasting, open source
- **Contras**: Documenta√ß√£o limitada

##### 4. Informer / Autoformer
```python
from transformers import InformerModel, AutoformerModel
```
- **Descri√ß√£o**: Transformers otimizados para s√©ries temporais longas
- **Uso**: Long sequence time-series forecasting
- **Pr√≥s**: Eficiente para s√©ries longas, aten√ß√£o sparse
- **Contras**: Mais complexo de implementar

**Estrat√©gia de uso:**
1. **Baseline Hugging Face**: Testar Chronos zero-shot
2. **Fine-tuning**: Adaptar Chronos-T5-small aos dados brasileiros
3. **Compara√ß√£o**: Avaliar vs modelos tradicionais (LSTM custom)
4. **Transfer Learning**: Usar embeddings de modelos pr√©-treinados como features

**Links:**
- Chronos: https://huggingface.co/amazon/chronos-t5-small
- Lag-Llama: https://huggingface.co/time-series-foundation-models/Lag-Llama
- TimeGPT: https://nixtla.github.io/nixtla/

---

### üìä Interpretabilidade e An√°lise

**Bibliotecas:**
```python
# Interpretabilidade
shap==0.43.0             # SHAP values (Chen & Moraga, 2025)
lime==0.2.0              # Local Interpretable Model-agnostic Explanations
eli5==0.13.0             # Feature importance

# Visualiza√ß√£o
plotly==5.17.0           # Gr√°ficos interativos
matplotlib==3.8.0        # Gr√°ficos est√°ticos
seaborn==0.13.0          # Visualiza√ß√µes estat√≠sticas
folium==0.15.0           # Mapas interativos
```

**Justificativa:**
- SHAP: Estado da arte em interpretabilidade, usado em trabalhos similares
- Plotly: Dashboards interativos de qualidade

---

### üóÑÔ∏è Processamento de Dados Geoespaciais

**Bibliotecas:**
```python
# Dados Geoespaciais
geopandas==0.14.0        # DataFrames geoespaciais
rasterio==1.3.9          # Processamento de rasters (CHIRPS, ERA5)
xarray==2023.10.0        # Dados multidimensionais (NetCDF)
earthengine-api==0.1.377 # Google Earth Engine

# Zonal Statistics
rasterstats==0.19.0      # Estat√≠sticas zonais (clima por munic√≠pio)
shapely==2.0.2           # Geometrias
```

**Justificativa:**
- GeoPandas: Padr√£o para dados geoespaciais em Python
- Rasterio/xarray: Processar dados clim√°ticos de sat√©lite (NetCDF, GeoTIFF)
- Earth Engine: Acesso a dados clim√°ticos pr√©-processados

---

### üöÄ Deployment e Produtiza√ß√£o

#### Dashboard e Visualiza√ß√£o

**Op√ß√£o 1: Streamlit (RECOMENDADO para TCC)**
```python
streamlit==1.28.0
```
- **Pr√≥s**: F√°cil de desenvolver, gratuito no Streamlit Cloud
- **Contras**: Menos customiz√°vel

**Op√ß√£o 2: Plotly Dash**
```python
dash==2.14.0
```
- **Pr√≥s**: Mais customiz√°vel, componentes React
- **Contras**: Requer mais c√≥digo

**Op√ß√£o 3: Gradio**
```python
gradio==4.0.0
```
- **Pr√≥s**: Focado em ML, integra√ß√£o com Hugging Face Spaces
- **Contras**: Menos flex√≠vel para dashboards complexos

---

#### API de Previs√£o

**FastAPI (RECOMENDADO)**
```python
fastapi==0.104.0
uvicorn==0.24.0
```

**Exemplo de endpoint:**
```python
@app.post("/predict")
async def predict_dengue(
    municipality: str,
    weeks_ahead: int = 4
):
    # Carregar modelo
    # Fazer previs√£o
    # Retornar JSON
    return {
        "municipality": municipality,
        "predictions": [...],
        "alert_level": "amarelo"
    }
```

**Deployment:**
- **Cloud Run** (GCP): Serverless, escala autom√°tica
- **AWS Lambda** + API Gateway
- **Heroku** (free tier para desenvolvimento)

---

### üîß MLOps e Versionamento

**Ferramentas:**

| Ferramenta | Uso | Custo |
|-----------|-----|-------|
| **Git + GitHub** | Versionamento de c√≥digo | Gratuito |
| **DVC** (Data Version Control) | Versionamento de dados/modelos | Gratuito |
| **MLflow** | Tracking de experimentos | Gratuito (self-hosted) |
| **Weights & Biases** | Tracking de experimentos | Gratuito (tier acad√™mico) |
| **Docker** | Containeriza√ß√£o | Gratuito |

**Workflow proposto:**
```
1. Desenvolvimento local (VS Code + Jupyter)
2. Tracking de experimentos (MLflow / W&B)
3. Versionamento (Git + DVC)
4. Treinamento em cloud (Vertex AI / SageMaker)
5. Deployment (Cloud Run / Lambda)
```

---

### üì¶ Stack Completo Recomendado

#### Para Desenvolvimento
```
- OS: Linux (WSL2 no Windows) / macOS
- IDE: VS Code + Jupyter Lab
- Python: 3.9 - 3.11
- Ambiente: conda ou venv
```

#### Para Dados
```
- Armazenamento: Google Cloud Storage (raw) + BigQuery (processed)
- Formato: Parquet (eficiente) + CSV (backup)
- Banco geoespacial: PostGIS (se necess√°rio)
```

#### Para Modelagem
```
- Baseline: SARIMA (statsmodels), Prophet
- ML: XGBoost, Random Forest (scikit-learn)
- DL: LSTM (TensorFlow/Keras), Chronos (Hugging Face)
- Interpretabilidade: SHAP
```

#### Para Deployment
```
- Dashboard: Streamlit Cloud (gratuito)
- API: FastAPI + Cloud Run
- Monitoring: Google Cloud Monitoring
```

---

### üí∞ Estimativa de Custos

| Item | Op√ß√£o Gratuita | Op√ß√£o Paga | Recomendado TCC |
|------|----------------|------------|-----------------|
| **Armazenamento** | GitHub (c√≥digo) | GCP $10/m√™s | GCP (cr√©ditos) |
| **Processamento** | Google Colab | GCP $50/m√™s | Colab Pro $10 |
| **Dashboard** | Streamlit Cloud | Cloud Run $10/m√™s | Streamlit Cloud |
| **GPU (DL)** | Colab Free | Colab Pro+ $50/m√™s | Colab Pro |
| **Tracking** | MLflow local | W&B $49/m√™s | W&B free tier |
| **TOTAL** | **$0** | **$169/m√™s** | **$10/m√™s** |

**Recomenda√ß√£o:** Usar stack gratuita + Colab Pro ($10/m√™s) √© suficiente para o TCC.

---

### üéì Justificativa Acad√™mica das Escolhas

#### Por que Hugging Face?
- **Estado da arte**: Modelos foundation representam o cutting edge
- **Reprodutibilidade**: Modelos pr√©-treinados com checkpoints p√∫blicos
- **Transfer learning**: Aproveitar conhecimento de outras s√©ries temporais
- **Compara√ß√£o justa**: Avaliar modelos tradicionais vs foundation models

#### Por que Google Cloud?
- **Cr√©ditos educacionais**: $300 + cr√©ditos adicionais
- **Earth Engine**: Acesso f√°cil a dados clim√°ticos
- **Ecosistema integrado**: Storage ‚Üí BigQuery ‚Üí Vertex AI ‚Üí Deployment
- **Escalabilidade**: Come√ßar pequeno, escalar se necess√°rio

#### Por que TensorFlow (vs PyTorch)?
- **Integra√ß√£o GCP**: Vertex AI otimizado para TensorFlow
- **Keras**: API simples e did√°tica
- **TensorFlow Lite**: Deploy em dispositivos m√≥veis (trabalho futuro)
- **Documenta√ß√£o**: Mais recursos para s√©ries temporais

---

### üìö Recursos de Aprendizado

**Para Hugging Face:**
- Curso: https://huggingface.co/learn/nlp-course
- Documenta√ß√£o: https://huggingface.co/docs/transformers
- Hub: https://huggingface.co/models

**Para Google Cloud:**
- Qwiklabs: https://www.qwiklabs.com/ (labs gratuitos)
- Documenta√ß√£o: https://cloud.google.com/docs
- Coursera: "Google Cloud Big Data and Machine Learning Fundamentals"

**Para S√©ries Temporais:**
- Livro: "Forecasting: Principles and Practice" (Hyndman & Athanasopoulos)
- Curso: "Time Series Analysis with Python" (Udemy)

---

### ‚úÖ Decis√µes Finais

**Stack escolhido:**

```yaml
Infrastructure:
  - Cloud: Google Cloud Platform (cr√©ditos educacionais)
  - Storage: Cloud Storage (raw) + BigQuery (processed)
  - Compute: Vertex AI Notebooks + Colab Pro

Data Processing:
  - Language: Python 3.10
  - Geospatial: GeoPandas, Rasterio, Earth Engine
  - ETL: Cloud Functions (serverless)

Modeling:
  - Baseline: SARIMA (statsmodels), Prophet
  - ML: XGBoost, Random Forest
  - DL: LSTM (TensorFlow/Keras)
  - Foundation: Chronos-T5 (Hugging Face)
  - Interpretability: SHAP

Deployment:
  - Dashboard: Streamlit Cloud
  - API: FastAPI + Cloud Run
  - Tracking: Weights & Biases (free tier)
  - Version Control: Git + DVC
```

**Crit√©rios de escolha:**
1. ‚úÖ **Custo zero ou baixo**: Cr√©ditos educacionais + free tiers
2. ‚úÖ **Reprodutibilidade**: C√≥digo e modelos p√∫blicos
3. ‚úÖ **Escalabilidade**: Funciona local, pode escalar para cloud
4. ‚úÖ **Estado da arte**: Inclui modelos foundation (Hugging Face)
5. ‚úÖ **Documenta√ß√£o**: Ampla comunidade e recursos de aprendizado

---

## ÔøΩüîÑ Pr√≥ximos Passos

Com base nos trabalhos similares, as pr√≥ximas etapas deste TCC s√£o:

1. ‚úÖ **Definir baseline**: SARIMA e Prophet (inspirado em InfoDengue)
2. ‚úÖ **Implementar ML**: Random Forest e XGBoost (Roster et al.)
3. ‚úÖ **Implementar DL**: LSTM com SHAP (Chen & Moraga)
4. ‚úÖ **Testar Foundation Models**: Chronos (Hugging Face) com fine-tuning
5. ‚úÖ **Feature engineering**: Lags clim√°ticos, efeitos espaciais
6. ‚úÖ **Valida√ß√£o robusta**: Temporal e geogr√°fica
7. ‚úÖ **Interpretabilidade**: SHAP, an√°lise de lags por regi√£o
8. ‚úÖ **Sistema de alerta**: Calibra√ß√£o de limiares
9. ‚úÖ **Deployment**: Dashboard Streamlit + API FastAPI

---

*√öltima atualiza√ß√£o: Novembro 2025*
*Vers√£o: 1.1*
