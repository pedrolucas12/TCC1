\chapter{Metodologia}
\label{cap:metodologia}

Este capítulo descreve detalhadamente o fluxo metodológico adotado, desde a engenharia de dados até a estratégia de análise estatística, garantindo a reprodutibilidade científica do estudo. A abordagem metodológica é quantitativa, descritiva e analítica, baseada em dados secundários de domínio público.

\section{Pipeline de Engenharia de Dados}

Dada a heterogeneidade das fontes de dados (SINAN e INMET), foi necessário desenvolver um \textit{pipeline} computacional robusto em linguagem Python para a extração, transformação e carga (ETL) das informações.

\subsection{1. Coleta e Padronização}
Os dados foram coletados de forma automatizada. Para os dados do INMET, que originalmente apresentam frequência horária ou diária, foi aplicado um processo de agregação temporal para compatibilizá-los com a granularidade semanal dos dados epidemiológicos.
\begin{itemize}
    \item Para a variável \textbf{Precipitação}, utilizou-se a soma acumulada da semana.
    \item Para as variáveis de \textbf{Temperatura, Umidade e Pressão}, utilizou-se a média aritmética das observações diárias.
    \item As datas foram padronizadas para o formato ISO 8601 (YYYY-MM-DD) e alinhadas pela data de início da Semana Epidemiológica (SE), que convencionalmente se inicia aos domingos.
\end{itemize}

\subsection{2. Tratamento e Unificação}
Foi realizada uma inspeção de qualidade dos dados para identificar valores espúrios (\textit{outliers} impossíveis, ex: temperatura de 200°C) ou dados faltantes (\textit{missing values}). Pequenas lacunas nas séries climáticas foram preenchidas utilizando interpolação linear, um método adequado para variáveis físicas contínuas. Em seguida, os \textit{datasets} de clima e saúde foram unificados (\textit{merged}) em uma única estrutura tabular, resultando em uma série temporal multivariada com 156 observações semanais.

\section{Análise Estatística Exploratória}

Antes da modelagem, realizou-se uma investigação profunda da estrutura de correlação dos dados para fundamentar a seleção de atributos (\textit{Feature Selection}).

\subsection{Correlação e Defasagem Temporal (Lags)}
A relação entre clima e dengue não é instantânea. O ciclo biológico impõe um atraso natural. Para capturar esse fenômeno, utilizou-se a Função de Correlação Cruzada (\textit{Cross-Correlation Function} - CCF).
Calculou-se a correlação de Pearson entre a série de casos ($Y_t$) e as séries climáticas defasadas ($X_{t-k}$) para $k = 0, 1, ..., 8$ semanas.
\[
r_k = \frac{\sum_{t=k+1}^T (y_t - \bar{y})(x_{t-k} - \bar{x})}{\sqrt{\sum_{t=1}^T (y_t - \bar{y})^2} \sqrt{\sum_{t=1}^T (x_t - \bar{x})^2}}
\]
Esse procedimento permite identificar, por exemplo, se a chuva de 2 meses atrás tem maior poder preditivo sobre os casos atuais do que a chuva da semana corrente.

\subsection{Teste de Causalidade de Granger}
Para ir além da simples correlação e investigar a precedência temporal estatística, aplicou-se o Teste de Causalidade de Granger. O teste avalia se a inclusão de valores passados de uma variável $X$ (Clima) reduz significativamente o erro de previsão da variável $Y$ (Casos), em comparação com um modelo que usa apenas os valores passados de $Y$.
A verificação foi feita para defasagens de 1 a 4 semanas, considerando um nível de significância de 5\% ($p < 0,05$).

\section{Planejamento da Modelagem Preditiva (TCC 2)}

A fase de construção dos modelos preditivos, a ser executada na etapa seguinte da pesquisa (TCC 2), seguirá uma abordagem experimental rigorosa.

\subsection{Algoritmos Selecionados}
\begin{enumerate}
    \item \textbf{SARIMA:} Será implementado utilizando a biblioteca \texttt{statsmodels}, com seleção automática de hiperparâmetros ($p,d,q$) e ($P,D,Q$) baseada no critério de informação de Akaike (AIC).
    \item \textbf{XGBoost:} Será implementado via biblioteca \texttt{xgboost}, com otimização de hiperparâmetros (taxa de aprendizado, profundidade da árvore) via \textit{Grid Search}.
    \item \textbf{LSTM:} Será construída com \texttt{TensorFlow/Keras}, testando arquiteturas com camadas de \textit{Dropout} para evitar \textit{overfitting} e camadas densas para a regressão final.
\end{enumerate}

\subsection{Estratégia de Validação e Métricas}
Dada a natureza temporal dos dados, a validação tradicional (separação aleatória treino/teste) é inadequada, pois violaria a ordem cronológica ("olhar para o futuro"). Será utilizada a validação \textbf{Walk-Forward} ou \textbf{Time Series Cross-Validation}.
O desempenho será mensurado pelas métricas:
\begin{itemize}
    \item \textbf{RMSE (Root Mean Squared Error):} Penaliza erros grandes, útil para prever picos.
    \item \textbf{MAE (Mean Absolute Error):} Mede o erro médio absoluto, de fácil interpretação.
\end{itemize}
