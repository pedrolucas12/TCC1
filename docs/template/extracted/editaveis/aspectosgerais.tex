\chapter{Aspectos Gerais}

\section{Bases de Dados}

Para a realização deste estudo, foi construída uma base de dados unificada cobrindo integralmente as semanas epidemiológicas dos anos de 2022, 2023 e 2024. A série temporal resultante contém 156 semanas de observações contínuas, sem lacunas temporais, permitindo uma análise robusta da dinâmica da doença no Distrito Federal.

\subsection{Dados Epidemiológicos (SINAN/InfoDengue)}
Os dados de casos de dengue foram obtidos através da API pública do projeto InfoDengue, que cura e disponibiliza dados do Sistema de Informação de Agravos de Notificação (SINAN).
\begin{itemize}
    \item \textbf{Fonte:} InfoDengue (API v1).
    \item \textbf{Localidade:} Município de Brasília (Geocódigo IBGE: 5300108).
    \item \textbf{Período:} Semana Epidemiológica 01 de 2022 até a Semana 52 de 2024.
    \item \textbf{Variáveis principais:} Casos notificados (confirmados + suspeitos), incidência por 100 mil habitantes e data de início da semana epidemiológica.
\end{itemize}

\subsection{Dados Meteorológicos (INMET)}
Os dados climáticos foram extraídos dos registros históricos do Instituto Nacional de Meteorologia (INMET).
\begin{itemize}
    \item \textbf{Fonte:} Estação Meteorológica Automática de Brasília (Código: A001).
    \item \textbf{Localização:} Latitude -15.789, Longitude -47.925, Altitude 1161m.
    \item \textbf{Processamento:} Os dados originais, coletados em frequência horária/diária, foram agregados semanalmente para pareamento com os dados epidemiológicos.
    \item \textbf{Variáveis utilizadas:}
    \begin{itemize}
        \item \textbf{Precipitação (mm):} Acumulado total da semana.
        \item \textbf{Temperatura (°C):} Média, mínima e máxima da semana.
        \item \textbf{Umidade Relativa (\%):} Média semanal.
        \item \textbf{Pressão Atmosférica e Vento:} Médias semanais.
    \end{itemize}
\end{itemize}

\section{Metodologia de Coleta e Processamento}

A coleta foi totalmente automatizada por meio de scripts desenvolvidos em linguagem Python, garantindo a reprodutibilidade e a fácil atualização dos dados. O \textit{pipeline} de dados consistiu nas seguintes etapas:

\begin{enumerate}
    \item \textbf{Requisição e Download:} Scripts específicos consultaram a API do InfoDengue e processaram os arquivos brutos (CSV) do INMET.
    \item \textbf{Limpeza e Tratamento:} Remoção de colunas irrelevantes, tratamento de valores nulos através de interpolação linear (para pequenas falhas em dados climáticos) e padronização de datas.
    \item \textbf{Agregação Temporal:} Conversão rigorosa dos dados climáticos diários para o padrão de Semanas Epidemiológicas (SE), utilizando a data de início da semana (domingo) como chave de agrupamento.
    \item \textbf{Fusão (Merge):} Unificação dos dois \textit{dataframes} em um único arquivo \textit{parquet/csv} final (`merged\_weekly`), contendo todas as variáveis alinhadas temporalmente.
\end{enumerate}

Esse processo resultou em um conjunto de dados estruturado, pronto para as análises estatísticas e o treinamento dos modelos de Inteligência Artificial.
